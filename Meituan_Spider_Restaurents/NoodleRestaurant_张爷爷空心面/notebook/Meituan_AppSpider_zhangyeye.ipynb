{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meituan AppSpider\n",
    "- Author: Yiran Jing\n",
    "\n",
    "Build Meituan AppSpider to collect customer comments of 'Macaroni of Zhang grandpa' chain restaurants\n",
    "\n",
    "Scraping content:\n",
    "1. Store location（店铺地址）\n",
    "2. Score of store （店铺评分）\n",
    "3. Consumption per person （人均消费）\n",
    "4. Business Hours （营业时间）\n",
    "5. Customer comments (网友点评)\n",
    "6. Recommended dishes (推荐菜)\n",
    "\n",
    "\n",
    "Reference: \n",
    "\n",
    "1. https://github.com/hahaha108/meituanAppSpider\n",
    "2. https://blog.csdn.net/slphahaha/article/details/81145404\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import urllib\n",
    "import urllib.request as urllib2\n",
    "import xlsxwriter\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.utils.project import get_project_settings\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ShenZhen Area\n",
    "- 目前美团有两个店铺，但是暂时都无评论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shanghai Area\n",
    "\n",
    "- 爬取上海地区张爷爷空心面的美团信息\n",
    "- 上海地区有五个连锁店铺,但目前只有两个店铺有用户评价，所以暂时只抓了两个店铺"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spider is ready for shanghai area\n"
     ]
    }
   ],
   "source": [
    "from spider_develop_shanghai import MeituanSpider_shanghai\n",
    "\n",
    "# save_mode ：txt存储为txt文件，csv存储为csv文件，无输入默认为csv\n",
    "spider_shanghai = MeituanSpider_shanghai()\n",
    "taglist_1, commentslist_1 = spider_shanghai.run(1000) # max read 10 pages, 10 comments in each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nanjing Area\n",
    "- 目前美团有两个店铺\n",
    "- 只有一个店铺有一则评论, 暂不抓取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TaiYuan Area\n",
    "- 目前美团有一家店铺：（茂业中心店）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spider is ready for Taiyuan area\n"
     ]
    }
   ],
   "source": [
    "from spider_develop_taiyuan import MeituanSpider_taiyuan\n",
    "\n",
    "# save_mode ：txt存储为txt文件，csv存储为csv文件，无输入默认为csv\n",
    "spider_taiyuan = MeituanSpider_taiyuan()\n",
    "taglist_2, commentslist_2 = spider_taiyuan.run(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TaiCang area\n",
    "- 目前美团有一家店铺："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spider is ready for Taicang area\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from spider_develop_taicang import MeituanSpider_taicang\n",
    "\n",
    "# save_mode ：txt存储为txt文件，csv存储为csv文件，无输入默认为csv\n",
    "spider_taicang = MeituanSpider_taicang()\n",
    "taglist_3, commentslist_3 = spider_taicang.run(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save result to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "taglist = taglist_1 + taglist_2 + taglist_3\n",
    "commentslist = commentslist_1 + commentslist_2 + commentslist_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Write_to_csv(fieldKey, file_name,datalist):\n",
    "    with open(file_name, 'w') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames= fieldKey)\n",
    "        writer.writeheader()\n",
    "        for data in datalist:\n",
    "            writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write user comments detail to csv\n",
    "fieldkey = ['店名',\"用户名\", '平均消费','星级','菜单','评价时间','用餐结束时间','评价']\n",
    "file_name = '../../../data/meituanZhangYeyeInfos/Zhangyeye_Comments.csv'\n",
    "Write_to_csv(fieldkey, file_name, commentslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write tag retails to csv file\n",
    "fieldKey = ['标签','累计数量']\n",
    "file_name = \"../../../data/meituanZhangYeyeInfos/Zhangyeye_Tags.csv\"\n",
    "Write_to_csv(fieldKey, file_name, taglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv(\"../../../data/meituanZhangYeyeInfos/Zhangyeye_Tags.csv\")\n",
    "## merge counts if they have same tags \n",
    "aggregation_functions = {'标签': 'first','累计数量': 'sum'}\n",
    "df_new = df.groupby(df['标签']).aggregate(aggregation_functions)\n",
    "df_new.to_csv('../../../data/meituanZhangYeyeInfos/Zhangyeye_Tags.csv',index=False,encoding='utf_8_sig') # utf_8_sig 为了避免中文乱码"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
